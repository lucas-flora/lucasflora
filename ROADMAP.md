# Roadmap for Building a 3D Terminal-Style Portfolio Site

## Project Overview and Tech Stack

LucasFlora.com will be a unique portfolio website presented as a retro terminal interface on a 3D CRT monitor. The plan is to combine modern web tech with a nostalgic aesthetic. Key technologies include:
	•	Next.js (React) – Provides project structure, routing, and easy deployment. The site will mostly run as a client-side app, but Next enables flexibility (e.g. a fallback static page for no-WebGPU users).
	•	Three.js with WebGPU – Powers the 3D graphics and shader effects. We’ll use Three.js’s latest WebGPU renderer to leverage GPU features and modern shading (WGSL). No need to support old WebGL, since we’ll provide a fallback for non-WebGPU browsers.
	•	React-Three-Fiber (R3F) – Integrates Three.js with React, letting us build the 3D scene as React components. This allows us to manage state and content easily in React while rendering the scene in Three.js ￼. An open-source experiment has shown this approach working well (using Three.js + R3F) ￼.
	•	Canvas/Konva for Screen Content – We can render the terminal text and UI onto an off-screen HTML5 canvas (or use a library like React-Konva) and use that canvas as a texture on the 3D screen ￼. This means the on-screen content can be built with familiar React tools (text, images, etc.) and then displayed in the 3D scene ￼.
	•	Shaders and Post-Processing – Custom shader effects (written in WGSL for WebGPU) will create the CRT screen look (scanlines, curvature, glow). We’ll also use a bloom post-processing pass for glowing highlights. All of this will be done with Three.js’s WebGPU capabilities.

Development Strategy: We will build a minimum viable product (MVP) first that demonstrates the full pipeline end-to-end (basic terminal output on a 3D screen with CRT and bloom effects). Then we’ll iterate with more features. This ensures we “lock in” the core architecture early and have a working prototype before adding complexity. Given this is a personal project, we can keep formal testing light – quick manual testing is fine (no need to over-engineer test suites at this stage). Content can be hard-coded for now, but we’ll structure it to allow fetching or dynamic loading later without major rewrites.

## Phase 1 – MVP: Basic 3D Terminal in a CRT Monitor

In Phase 1, the goal is to implement a simple but complete vertical slice of the experience. The focus is on the core structure: a terminal-like interface that accepts input and outputs lines, all rendered on a 3D monitor with retro effects. Below are the steps to achieve the MVP:
	1.	Initialize Project & Enable WebGPU: Set up a new Next.js project and install Three.js (r150+ for WebGPU support) and React-Three-Fiber. Configure the app to only use the 3D canvas on the client (e.g. load the R3F Canvas in a <dynamic> Next.js component to avoid SSR issues). Initialize the Three.js WebGPU renderer. For example, use import { WebGPURenderer } from 'three/addons/renderers/WebGPURenderer.js'; and fall back to a simple message if unavailable. In code, check for WebGPU support with if (!navigator.gpu) { /* fallback */ } ￼. This ensures the site can detect if WebGPU is supported and either proceed or activate a fallback mode.
	2.	Build the 3D Scene – Monitor Screen & Frame: Create a basic 3D scene containing a screen plane and a monitor frame geometry. The screen will be a slightly curved plane (convex toward the user). We can achieve curvature by subdividing a plane and offsetting vertices, or by using a fragment shader for distortion. For the MVP, even a flat plane is okay; we can introduce curvature in a later iteration. The frame (monitor body) can start as a simple box or hollow rectangular prism surrounding the screen. Make its size parametric based on the screen dimensions (which in turn can be tied to the browser window size or aspect ratio). For instance, if the screen plane is sized to match the window’s aspect ratio, the frame’s width/height can derive from that, ensuring the whole model scales with the viewport. Include a small power LED as a sphere or tiny cylinder on the frame (for now just a mesh with emissive material). Use basic lighting in the scene (an ambient light plus maybe a dim directional light) so that the frame is visible and can show specular highlights. Position the camera in front of the monitor (e.g. a few units back, looking straight at the screen). Adjust the camera’s FOV to capture the whole monitor with a bit of margin.
	3.	Implement a Basic Terminal Interface: Develop the terminal UI within the 3D screen. Start with a very simple interaction: an input field and a log of text lines (much like a command-line interface). One straightforward approach is to maintain an array of “terminal entries” in React state. Each entry could be an object with a type (e.g. "text") and content (e.g. the string to display). When the user types and presses Enter, capture that input (via a hidden HTML <input> or by listening for key events) and append a new entry to the array. For MVP, the “commands” don’t need to actually do anything functional – they can just echo the input or display a preset message. The key is that hitting Enter causes a new line of output to appear at the bottom of the screen (and perhaps the input prompt moves to a new line, simulating a terminal scroll). To render the text on the 3D screen, use a canvas texture: create an off-screen <canvas> and draw the text lines onto it (using CanvasRenderingContext2D.fillText, or using a library like Konva for richer text rendering). Update this canvas whenever new text is added, and update the Three.js texture (e.g. using Texture.needsUpdate = true). The canvas approach allows us to leverage normal font rendering and even HTML/CSS if needed, then display the result in our scene ￼. (In the future, we can replace direct canvas drawing with a React-Konva component for more complex screen layouts, as one experiment did to reuse React UI patterns on the screen ￼.) For MVP simplicity, hard-code a monospace font and draw basic text. Ensure the text color contrasts with the background (classic green or amber on black would give a retro vibe). Also implement a blinking cursor (for authenticity): this could be done by periodically drawing/erasing an underscore at the end of the current input text on the canvas.
	4.	Apply a CRT Screen Shader (Scanline Effect): With the text appearing on the screen, enhance it with a shader to simulate a CRT look. Scanlines are a crucial effect – these are horizontal lines or bands that give the look of an old monitor. We can achieve this by writing a custom fragment shader that darkens every few horizontal pixel rows, or by overlaying a semi-transparent striped texture on the screen material. For the MVP, a simple approach is to use a fragment shader modification: for each fragCoord.y, modulate brightness so that alternating lines are slightly dimmer. Keep the effect subtle (small opacity) to avoid obscuring text.  ￼The scanline effect “simulates scanlines reminiscent of old CRT displays, creating a nostalgic or stylized visual effect… enhancing the retro aesthetic” ￼. We’ll implement it as part of the screen’s material shader. Since we’re using WebGPU, we’ll write this shader in WGSL or use Three.js’s node material system. Another aspect is curvature and glare: old CRTs have a curved glass that causes slight distortion and a soft highlight at the edges. For MVP, we might skip advanced distortion, but we can introduce a mild fish-eye effect by warping the UV coordinates in the fragment shader (barrel distortion). Similarly, we can simulate a glass reflection/highlight by adding a specular component or an env map: for example, a faint white bloom near the screen’s curved edges to suggest reflective glass. (In the future, this could be improved with a more sophisticated shader or even a physical glass cover in front of the screen.) For now, focusing on scanlines and maybe a minor vignette on edges is sufficient.

  5.	Add Bloom for Screen Glow: To enhance the visual appeal, integrate a bloom post-processing effect in the rendering pipeline. Bloom will make bright areas (like the screen content and the power LED) bleed light and glow. With Three.js’s WebGPU renderer, post-processing might use a different path than traditional EffectComposer, but the concept is similar. We can utilize Three.js’s built-in UnrealBloomPass (if available for WebGPU) or manually render a secondary pass for bloom. Start with moderate bloom settings – we want the screen to glow subtly, not wash out the text. The emissive intensity of the screen material can be increased so that the bloom highlights it. The power LED mesh should also have an emissive material (e.g. a bright green) so that bloom makes it appear to glow realistically. After setting up bloom, test that the text is still readable (bloom threshold might need adjustment so that only the brightest whites bloom, not the dark background or dim text). The bloom effect will give the monitor a “alive” look: the screen and LED will cast a faint light on the monitor frame and feel like a real, powered device. If Three.js WebGPU supports light emission affecting other objects, we could also explore making the screen itself act as an actual light (area light) shining on the frame. That might be complex, so bloom + an ambient light might suffice for the illusion. The final outcome of Phase 1 is an interactive terminal on a stylized 3D CRT monitor: you can type a command, see it appear on the curved screen with scanline effects, and the screen glows convincingly in the dark scene.
	6.	Implement Fallback for Non-WebGPU Browsers: Since WebGPU is new and not all users may have support, plan a simple fallback. Using the detection from step 1, if WebGPU isn’t supported, redirect or swap the UI to a basic portfolio gallery page. This could be a standard Next.js page with static content – for example, a list of projects or an “About Me” section. It won’t have the 3D interactive terminal, but it ensures users can still access core information. Keep the design of fallback simple and lightweight. In Next.js, this can be handled by dynamic import or conditional rendering: e.g. if navigator.gpu is undefined, show <NoWebGPUScreen /> instead of the R3F <Canvas>. The fallback content can be just hard-coded HTML/CSS for now (maybe even reuse the same data that the terminal would show, but in a more conventional format). This satisfies the requirement that users without WebGPU automatically see the portfolio content in a basic way. We’ll also provide a manual toggle link (like “View basic site”) so that users can switch if they prefer or if performance is an issue.

With Phase 1 complete, we will have a baseline product: the main pipeline (input → content → 3D render → shader effects) is demonstrated. The website at this stage is already functional and showcases the intended style, albeit with minimal content and features. Next, we can build on this foundation to add more advanced interactions and polish.

## Phase 2 – Enhancements and Advanced Features

After the MVP is up and running, Phase 2 will expand the functionality, content, and visual fidelity of the site. The goal is to turn the basic prototype into a rich, feature-complete portfolio. We will do this in modular increments, ensuring the core stays stable while new layers are added. Key focus areas:
	•	Robust Modular Content System: Refine the terminal “entries” structure to be more powerful. We’ll design a flexible system where each entry in the terminal log can be of various types and render dynamic content. For example, besides plain text lines, we might have entries that display an image or play a video, or even show an interactive 3D model (using Three.js within that line). To achieve this, create an interface or base class for Terminal entries (with properties like type, maybe a common render method or React component). Implement specific entry subclasses/components, such as TextEntry, ImageEntry, ModelEntry, etc. In React, this could be as simple as checking the entry type and rendering accordingly (e.g. if entry.type === 'image', return an <img> texture on the canvas or a sprite in the 3D scene). The inheritance or component composition approach ensures we can add new content types easily. Content should be stored in a way that is easy to manage: possibly as JSON or Markdown files that can be parsed into entries. For now, data can remain hard-coded (e.g. an array of objects defined in a file), but we will keep the door open to fetch content from elsewhere (like a CMS or external API) with minimal changes. Structuring content this way makes it searchable and sortable too – we could implement a search command that filters or highlights entries (since we have them in an array, we can scan for keywords). The terminal should also support basic navigation like scrolling up to see older entries (if content overflows the visible area). We might implement a scrollbar in the 3D UI or keyboard shortcuts (e.g. PageUp/PageDown) to scroll the camera or move through the content array.
	•	Command Parser and Interactivity: Enhance the input handling so that the terminal isn’t just an echo, but can execute commands. Define a set of commands (like a real terminal or a fake “shell” for the portfolio). For example:
	•	Typing help could list available commands (about, projects, contact, etc.).
	•	about might display a brief bio.
	•	projects could list portfolio pieces (each as an entry, possibly with clickable links or images).
	•	open <project-name> might “open” a project entry, which could trigger loading a 3D model or navigating to a detail view.
Internally, implement a simple parser: you can split the input string and match against known commands. Upon recognizing a command, push the appropriate output entries to the terminal. This simulates a shell-like experience for the user, making the site fun to explore. Keep the system flexible: it should be easy to add new commands or alias in the future. (For instance, a command gallery could switch to a different mode, etc.) Since this is all in JavaScript, we can be creative – e.g. allow some commands to affect the 3D scene (maybe a command to toggle the room lights or spin the monitor, as a playful touch).
	•	LLM Integration (Chatbot Mode): Incorporate the “LLM magic” as mentioned – essentially a chatbot that acts as a virtual “Lucas Flora assistant” inside the terminal. This could be triggered by a specific command (e.g. typing chat or even any input that isn’t a recognized command could route to the AI for an answer). We can integrate a large language model API (such as OpenAI’s API) to handle questions about you or the content. For example, a user might type “What is Lucas’s expertise?” and the chatbot can respond with a pre-programmed or AI-generated answer about your skills and background. To implement this, we’d set up an API route in Next.js or call a third-party API from the client. The prompt can be tailored with your portfolio info so that the AI responds accurately. Start with a basic Q&A setup (perhaps using a free or local model if possible to avoid cost, depending on requirements). The chatbot’s answer would be added as a new terminal entry (with a distinctive prefix like “AI:” or a different color to differentiate it). This feature will make the site more interactive and personalized, as visitors can ask questions in natural language. We will need to handle unknown questions gracefully (maybe a witty “I don’t know that yet, but I’m learning!” response). Also, implement a rate-limit or cooldown if using an API, to avoid spamming the service. This AI feature can be expanded over time, but even a simple version adds a “wow” factor to the site.
	•	Advanced CRT Visual Effects: With basic scanlines in place, we can now push the CRT illusion further for visual interest. One improvement is to implement curved screen distortion more accurately. We can modify the vertex shader (or use a postprocessing pass) to bend the corners of the screen texture, making it convincingly convex. Another effect: add a subtle phosphor glow/afterglow – old CRTs sometimes have a ghosting trail. This could be simulated by briefly retaining the previous frame or using a shader that blends a bit of the last frame’s brightness (though careful not to blur text). We should also refine the reflective glare on the screen. For instance, we could overlay a faint reflection texture (like an environment map of a room or simply a gradient) that moves slightly with camera angle, to mimic a glass reflection. The monitor’s frame itself could be given more detail: perhaps beveled edges, vents, or screws modeled in, to enhance realism. All geometry should remain parametric (driven by formulas, not static models) – for example, we can programmatically generate rounded edges on the frame using a Torus or cylinder pieces at the corners, or use Three.js ExtrudeGeometry to create a rounded rectangular frame profile. The power LED can be made functional (e.g. blinking or color-changing on certain events, just for fun). Finally, consider the overall scene ambiance: we might introduce a very dim environment map or background to give subtle reflections on the monitor. We could also darken the surrounding so the monitor really “pops” as the focal point (maybe even place the monitor on a small 3D desk or have a faint wall behind it, though that’s optional and can be a later addition). Also, this is a good time to tweak camera controls – perhaps allow the user to click-and-drag to slightly rotate the view of the monitor (not fully around, but a small left-right rotation as if they’re peeking around it). This interactivity (if implemented) can make the experience feel more game-like. If doing that, ensure the camera controls don’t interfere with the terminal typing (maybe only activate rotation on a certain key or button, or when the terminal is “locked”). Depth of field (DOF) can be added now or later: a DOF post-effect could focus on the screen and slightly blur the monitor frame or background when the camera is at certain angles, adding a cinematic touch.
	•	Performance Tuning and Testing: At this stage, the application is getting complex, so we should optimize and test on various devices. Even though we won’t invest heavily in automated testing (since it’s a personal site and we can iterate quickly), some QA is wise. For performance, monitor the frame rate with all effects on – WebGPU is powerful, but features like bloom and custom shaders can be heavy. Profile using browser dev tools; ensure the canvas texture updates for the terminal aren’t too slow (if they are, consider only re-drawing the parts that changed, or limiting the rate of text updates). Also test memory usage – e.g. if many entries are added, does the canvas or array grow too large? Perhaps implement a limit (e.g. only keep last N lines, or paginate older content) if needed. Check the site in multiple browsers that support WebGPU (Chrome, Edge, maybe Firefox with flags, and in the future Safari when available). Also test the fallback in browsers without WebGPU (it should automatically show the simple version). Since we aren’t doing heavy unit tests, rely on manual testing and fixing issues as they arise. Because it’s your personal site, rapid tweaks are acceptable – you can be nimble with updates and deployments.
	•	Content Integration & Deployment: With the structure ready, start filling in real content. Replace placeholder text with your actual introductions, project descriptions, images, links, etc. This might involve writing some JSON files or creating React components that represent portfolio items, which the terminal commands will display. Ensure that adding or editing content is straightforward – for example, if you have a list of projects, you might keep them in a separate module that both the main site and the fallback page can import, so content stays in sync. Think about SEO (search engine optimization) as well: since much of the content is in a 3D canvas, consider adding a basic <noscript> or an HTML snapshot of key info (like your name, titles of projects) for search engines or if JavaScript is disabled. Next.js can help by rendering a simplified static version of the page as the initial HTML (maybe just a message like “Loading Lucas’s Terminal… if you see this, your browser may not support the experience, please enable JS or use an updated browser”). Finally, deploy the site – Vercel is a good choice for Next.js projects. The WebGPU features might require HTTPS (likely needed for getUserMedia or certain APIs), so ensure the site is served over SSL (Vercel does that by default). After deployment, do one more round of testing in production (some differences can appear between dev and prod builds regarding performance).

By the end of Phase 2, LucasFlora.com will be a rich, interactive portfolio that stands out. It will have a fully functional retro terminal interface that not only looks cool with CRT shaders and 3D visuals, but is also practical – allowing visitors to learn about you and your work in an engaging way. The architecture will be modular and modern, making it easy to maintain and extend. You’ll be able to add new “commands” or content entries as your portfolio grows, and even experiment with more 3D or AI features given the flexible framework.

## Future Ideas and Conclusion

The roadmap above gets us to a comprehensive v1.0, but there’s always room for future innovation. Some ideas for later might include: a “gaming mode” where the user can navigate a 3D space around the monitor (turn off the terminal and explore a room), Easter eggs triggered by certain commands, or even multi-user interactions (imagine a chatroom inside the terminal). Thanks to the solid foundation (Next.js + React + Three.js), these features can be added without reinventing the wheel. Each part of the system (terminal UI, 3D rendering, content management) is decoupled enough to tweak independently.

In summary, the development will proceed from a simple prototype to an advanced interactive site in well-defined stages. We start by getting the basics right – a terminal on a 3D CRT screen with WebGPU – and then layer on the cool stuff like AI chat, rich content, and fancy shaders. By following this roadmap, we ensure that the project remains manageable and enjoyable to build, all while achieving the ultimate goal: a smart, modular, and visually striking personal website that truly reflects your creativity. Good luck, and enjoy the coding journey!